{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd7f7f6",
   "metadata": {},
   "source": [
    "# 2. Data preprocessing and TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4d9ac86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6090, 5)\n",
      "(1523, 5)\n"
     ]
    }
   ],
   "source": [
    "# Loading the Data \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "  train,\n",
    "  test_size=0.20,\n",
    "  stratify=train['target'],\n",
    "  random_state=42\n",
    ")\n",
    "\n",
    "# Checking the code\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd46d2d",
   "metadata": {},
   "source": [
    "## 2.1 Comparing two methods of Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09d9f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Regex-Based Cleaning\n",
    "\n",
    "def clean1(text):\n",
    "  text = text.lower() # lowercasing\n",
    "  text = re.sub(r'http\\S+', '', text) #removing the URL\n",
    "  text = re.sub(r'@\\w+','',text) #removing the @mentions\n",
    "  text = re.sub(r'[^a-z0-9\\s]',' ',text) #removing punctuation\n",
    "  text = re.sub(r'\\s+', ' ', text).strip() # Changing multiple spaces into one\n",
    "  return text\n",
    "\n",
    "# 2. Using the tweet-preprocessor Library\n",
    "import preprocessor as tp\n",
    "\n",
    "def clean2(text):\n",
    "  cleaned = tp.clean(text)\n",
    "  return cleaned.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4ffafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean1</th>\n",
       "      <th>clean2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wwp is serving more than 75k veterans. 52k O...</td>\n",
       "      <td>is serving more than 75k veterans 52k oif oef ...</td>\n",
       "      <td>. is serving more than k veterans. k oif/oef v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@RetiredFilth people in sydney woke up to the ...</td>\n",
       "      <td>people in sydney woke up to the whole sky bein...</td>\n",
       "      <td>people in sydney woke up to the whole sky bein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Side factory where worker electrocuted p...</td>\n",
       "      <td>south side factory where worker electrocuted p...</td>\n",
       "      <td>south side factory where worker electrocuted p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New #Free #Porn #Clip! Taking Of Hostages Dang...</td>\n",
       "      <td>new free porn clip taking of hostages dangerou...</td>\n",
       "      <td>new ! taking of hostages dangerous for favors ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Art World's Seismic Shift Back to the Oddb...</td>\n",
       "      <td>the art world s seismic shift back to the oddb...</td>\n",
       "      <td>the art world's seismic shift back to the oddb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  .@wwp is serving more than 75k veterans. 52k O...   \n",
       "1  @RetiredFilth people in sydney woke up to the ...   \n",
       "2  South Side factory where worker electrocuted p...   \n",
       "3  New #Free #Porn #Clip! Taking Of Hostages Dang...   \n",
       "4  The Art World's Seismic Shift Back to the Oddb...   \n",
       "\n",
       "                                              clean1  \\\n",
       "0  is serving more than 75k veterans 52k oif oef ...   \n",
       "1  people in sydney woke up to the whole sky bein...   \n",
       "2  south side factory where worker electrocuted p...   \n",
       "3  new free porn clip taking of hostages dangerou...   \n",
       "4  the art world s seismic shift back to the oddb...   \n",
       "\n",
       "                                              clean2  \n",
       "0  . is serving more than k veterans. k oif/oef v...  \n",
       "1  people in sydney woke up to the whole sky bein...  \n",
       "2  south side factory where worker electrocuted p...  \n",
       "3  new ! taking of hostages dangerous for favors ...  \n",
       "4  the art world's seismic shift back to the oddb...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing two methods\n",
    "\n",
    "train_df['clean1'] = train_df['text'].apply(clean1)\n",
    "train_df['clean2'] = train_df['text'].apply(clean2)\n",
    "\n",
    "val_df['clean1']   = val_df['text'].apply(clean1)\n",
    "val_df['clean2']   = val_df['text'].apply(clean2)\n",
    "\n",
    "sample = train_df[['text', 'clean1', 'clean2']].sample(5, random_state=42)\n",
    "sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b5841e",
   "metadata": {},
   "source": [
    "- Clean2 seems good at removing generic noise, such as numbers or hashtags, compare to clean 1 which preserves those informations.\n",
    "- However, Clean1 might introduce some noise beyond @mentions or URLs since it is more brute-force method. \n",
    "- For this challenge, however, preserving disaster-related keywords as well as removing noise would be important. Thus, we could make Clean 3 based on this result. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c7077",
   "metadata": {},
   "source": [
    "  - For this new cleaning method, we should\n",
    "    - Keep the word behind a hashtag\n",
    "    - Remove URLs and @mentions\n",
    "    - Preserve alphanumeric tokens\n",
    "    - Lowercasing\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a10793ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean1</th>\n",
       "      <th>clean2</th>\n",
       "      <th>clean3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wwp is serving more than 75k veterans. 52k O...</td>\n",
       "      <td>is serving more than 75k veterans 52k oif oef ...</td>\n",
       "      <td>. is serving more than k veterans. k oif/oef v...</td>\n",
       "      <td>is serving more than 75k veterans 52k oif oef ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@RetiredFilth people in sydney woke up to the ...</td>\n",
       "      <td>people in sydney woke up to the whole sky bein...</td>\n",
       "      <td>people in sydney woke up to the whole sky bein...</td>\n",
       "      <td>people in sydney woke up to the whole sky bein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Side factory where worker electrocuted p...</td>\n",
       "      <td>south side factory where worker electrocuted p...</td>\n",
       "      <td>south side factory where worker electrocuted p...</td>\n",
       "      <td>south side factory where worker electrocuted p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New #Free #Porn #Clip! Taking Of Hostages Dang...</td>\n",
       "      <td>new free porn clip taking of hostages dangerou...</td>\n",
       "      <td>new ! taking of hostages dangerous for favors ...</td>\n",
       "      <td>new free porn clip taking of hostages dangerou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Art World's Seismic Shift Back to the Oddb...</td>\n",
       "      <td>the art world s seismic shift back to the oddb...</td>\n",
       "      <td>the art world's seismic shift back to the oddb...</td>\n",
       "      <td>the art world s seismic shift back to the oddb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  .@wwp is serving more than 75k veterans. 52k O...   \n",
       "1  @RetiredFilth people in sydney woke up to the ...   \n",
       "2  South Side factory where worker electrocuted p...   \n",
       "3  New #Free #Porn #Clip! Taking Of Hostages Dang...   \n",
       "4  The Art World's Seismic Shift Back to the Oddb...   \n",
       "\n",
       "                                              clean1  \\\n",
       "0  is serving more than 75k veterans 52k oif oef ...   \n",
       "1  people in sydney woke up to the whole sky bein...   \n",
       "2  south side factory where worker electrocuted p...   \n",
       "3  new free porn clip taking of hostages dangerou...   \n",
       "4  the art world s seismic shift back to the oddb...   \n",
       "\n",
       "                                              clean2  \\\n",
       "0  . is serving more than k veterans. k oif/oef v...   \n",
       "1  people in sydney woke up to the whole sky bein...   \n",
       "2  south side factory where worker electrocuted p...   \n",
       "3  new ! taking of hostages dangerous for favors ...   \n",
       "4  the art world's seismic shift back to the oddb...   \n",
       "\n",
       "                                              clean3  \n",
       "0  is serving more than 75k veterans 52k oif oef ...  \n",
       "1  people in sydney woke up to the whole sky bein...  \n",
       "2  south side factory where worker electrocuted p...  \n",
       "3  new free porn clip taking of hostages dangerou...  \n",
       "4  the art world s seismic shift back to the oddb...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean3 based on Regex Cleaner\n",
    "def clean3(text):\n",
    "  text = text.lower() # lowercasing\n",
    "  text = re.sub(r\"#([a-z0-9_]+)\", r\"\\1\", text) # Hashtag to plain word\n",
    "  text = re.sub(r'http\\S+', \"\", text) # removing HTTP. URL\n",
    "  text = re.sub(r\"www\\.\\S+\", \"\", text) # removing WWW. URL\n",
    "  text = re.sub(r'@\\w+', \"\", text) # removing @mentions\n",
    "  text = re.sub(r\"[^a-z0-9\\s]\", \" \", text) #r emoving other characters other than a-z, 0-9 and whitespace\n",
    "  text = re.sub(r\"\\s+\", \" \", text).strip() # Changing multiple spaces into one\n",
    "  return text\n",
    "\n",
    "# Applying clean 3\n",
    "train_df['clean3'] = train_df['text'].apply(clean3)\n",
    "val_df['clean3']   = val_df['text'].apply(clean3)\n",
    "\n",
    "#comparing Clean 3\n",
    "sample = train_df[['text', 'clean1', 'clean2', 'clean3']].sample(5, random_state=42)\n",
    "sample.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c00efd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 scores by cleaner: {'clean1': 0.772162386081193, 'clean2': 0.7612687813021702, 'clean3': 0.772162386081193}\n"
     ]
    }
   ],
   "source": [
    "# Vectorize and Train TF-IDF for all cleaning methods\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate_cleaner (clean_col):\n",
    "  # Training vectorizer \n",
    "  vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "  X_tr = vectorizer.fit_transform(train_df[clean_col])\n",
    "  y_tr = train_df['target']\n",
    "\n",
    "  # Transform validation set\n",
    "  X_vl = vectorizer.transform(val_df[clean_col])\n",
    "  Y_vl = val_df['target']\n",
    "\n",
    "  # Fit logistic regression\n",
    "  model = LogisticRegression(max_iter=1000)\n",
    "  model.fit(X_tr, y_tr)\n",
    "\n",
    "  # Predict on validation and compute F1\n",
    "  preds = model.predict(X_vl)\n",
    "  return f1_score(Y_vl, preds), vectorizer, model\n",
    "\n",
    "# Evaluating all three cleaners\n",
    "results = {}\n",
    "\n",
    "for col in ['clean1', 'clean2', 'clean3']:\n",
    "    f1_val, vect_obj, model_obj = evaluate_cleaner(col) \n",
    "    results[col] = f1_val\n",
    "\n",
    "print(\"Validation F1 scores by cleaner:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1db809d",
   "metadata": {},
   "source": [
    "- clean1 and clean3 were tied at 0.772, whilst clean 2 was slightly lower score at 0.761.\n",
    "- We could guess that this is due to clean2 dropping numbers and hashtags.\n",
    "- Going forward with clean3 would be better, since it is designed to remove noise that is irrelevant. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78094a26",
   "metadata": {},
   "source": [
    "## 2.2 Retraining and Making first submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5c6f0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv created!\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "test['clean3'] = test['text'].apply(clean3)\n",
    "\n",
    "vect_full = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "X_full = vect_full.fit_transform(train_df['clean3'])\n",
    "y_full = train_df['target']\n",
    "\n",
    "lr_full = LogisticRegression(max_iter=1000)\n",
    "lr_full.fit(X_full, y_full)\n",
    "\n",
    "X_test = vect_full.transform(test['clean3'])\n",
    "test_preds = lr_full.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'target': test_preds\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"submission.csv created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3298fe5a",
   "metadata": {},
   "source": [
    "- Result: 0.79711 in Kaggle submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
